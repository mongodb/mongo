command_type: system
stepback: false


## Parameters for parameterized builds (see https://github.com/evergreen-ci/evergreen/wiki/Parameterized-Builds)
parameters:
  - key: patch_compile_flags
    description: "Additional SCons flags to be applied during scons compile invocations in this patch"


variables:
  ###
  # Leave this section uncommented to enable compile.
  _real_compile_amazon2: &_compile_amazon2
      - name: compile
        variant: compile-amazon2
      - name: schedule_global_auto_tasks
        variant: task_generation
  _real_compile_rhel70: &_compile_rhel70
      - name: compile
        variant: compile-rhel70
      - name: schedule_global_auto_tasks
        variant: task_generation
  _real_expansions: &_expansion_updates
    # TODO: Disable in SERVER-57226.
    - key: enable_detect_changes
      value: "true"
  ###

###
# **Or**: Leave this section uncommented to bypass/skip compile.
#  _skip_compile_amazon2: &_compile_amazon2
#      - name: schedule_global_auto_tasks
#        variant: task_generation
#  _skip_compile_rhel70: &_compile_rhel70
#      - name: schedule_global_auto_tasks
#        variant: task_generation
#  _skip_expansions: &_expansion_updates
#      # This is the normal (amazon2) "compile" artifact from https://evergreen.mongodb.com/version/sys_perf_4.4_78207ca380688c73b1a217f23d5b7c8803bef9cd
#      - key: mdb_binary_for_client
#        value: https://dsi-donot-remove.s3-us-west-2.amazonaws.com/compile_artifacts/mongodb-sys_perf_4.4_78207ca380688c73b1a217f23d5b7c8803bef9cd.tar.gz
#      - key: mdb_binary_for_server
#        value: https://dsi-donot-remove.s3-us-west-2.amazonaws.com/compile_artifacts/mongodb-sys_perf_4.4_78207ca380688c73b1a217f23d5b7c8803bef9cd.tar.gz
###

  _src_dir: &src_dir src/mongo
  _modules: &modules
    - enterprise
    - mongo-tools
    # - mongo
    - dsi
    - genny
    - signal-processing
    - workloads
    - linkbench
    - linkbench2
    - tsbs
    - mongo-perf
    - YCSB
    - benchmarks
    - py-tpcc


modules:
  ###
  # Same in every DSI project. Ensure that this block is synchronized with
  # evergreen-dsitest.yml, atlas/system_perf_atlas.yml, and src/dsi/onboarding.py
  # (search update-repos-here) in this repo, and etc/system_perf.yml and
  # etc/perf.yml in mongodb/mongo
  - name: dsi
    repo: git@github.com:10gen/dsi.git
    prefix: ${workdir}/src
    branch: master
  - name: genny
    repo: git@github.com:10gen/genny.git
    prefix: ${workdir}/src
    branch: master
  - name: signal-processing
    repo: git@github.com:10gen/signal-processing.git
    prefix: ${workdir}/src
    branch: master
  - name: workloads
    repo: git@github.com:10gen/workloads.git
    prefix: ${workdir}/src
    branch: master
  - name: linkbench
    repo: git@github.com:10gen/linkbench.git
    prefix: ${workdir}/src
    branch: master
  - name: linkbench2
    repo: git@github.com:10gen/linkbench2.git
    prefix: ${workdir}/src
    branch: master
  - name: tsbs
    repo: git@github.com:gregorynoma/tsbs.git
    prefix: ${workdir}/src
    branch: master
    ref: 225e713010463582712dca30ffcfc70c7d661663
  - name: mongo-perf
    repo: git@github.com:mongodb/mongo-perf.git
    prefix: ${workdir}/src
    branch: master
  - name: YCSB
    repo: git@github.com:mongodb-labs/YCSB.git
    prefix: ${workdir}/src
    branch: production
  - name: benchmarks
    repo: git@github.com:mongodb-labs/benchmarks.git
    prefix: ${workdir}/src
    branch: master
  - name: py-tpcc
    repo: git@github.com:mongodb-labs/py-tpcc.git
    prefix: ${workdir}/src
    branch: production
#  - name: mongo
#    repo: git@github.com:mongodb/mongo.git
#    prefix: ${workdir}/src
#    branch: master
  ###
  - name: enterprise
    repo: git@github.com:10gen/mongo-enterprise-modules.git
    prefix: src/mongo/db/modules
    branch: v5.2
  - name: mongo-tools
    repo: git@github.com:mongodb/mongo-tools.git
    prefix: mongo-tools/src/github.com/mongodb
    branch: master


###
# Same in every DSI project
pre:
  - func: f_other_pre_ops
  - func: f_dsi_pre_run
post:
  - func: f_dsi_post_run
  - func: f_other_post_ops
timeout:
  - func: f_dsi_timeout
  - func: f_other_timeout
###


functions:
  ###
  # Same in every DSI project
  f_dsi_pre_run:
    - command: manifest.load
    - command: expansions.update
      params:
        updates: *_expansion_updates
  f_run_dsi_workload:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          genny: ${genny_rev}
          signal-processing: ${signal-processing_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          tsbs: ${tsbs_rev}
          workloads: ${workloads_rev}
          mongo-perf: ${mongo-perf_rev}
          YCSB: ${YCSB_rev}
          benchmarks: ${benchmarks_rev}
          py-tpcc: ${py-tpcc_rev}
          # mongo: ${mongo_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi run_workload
    - command: shell.exec
      type: system
      params:
        script: ./src/dsi/run-dsi determine_failure -m SYSTEM
    - command: shell.exec
      type: setup
      params:
        script: ./src/dsi/run-dsi determine_failure -m SETUP
    - command: shell.exec
      type: test
      params:
        script: ./src/dsi/run-dsi determine_failure -m TEST
  f_dsi_post_run:
    # TODO: SERVER-57226 will let us move this json.send to after dsi's post_run.
    # This is preferred to keep DSI execution contiguous.
    - command: json.send
      params:
        name: perf
        file: ./build/LegacyPerfJson/perf.json
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi post_run
    - command: perf.send
      params:
        file: ./build/CedarReports/cedar_report.json
        aws_key: ${terraform_key}
        aws_secret: ${terraform_secret}
        bucket: genny-metrics
        region: us-east-1
        prefix: ${task_id}_${execution}
    - command: attach.results
      params:
        file_location: ./build/EvergreenResultsJson/results.json
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: ./build/Artifacts/DSIArtifacts.tgz
        remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/dsi-artifacts-${task_name}-${build_id}-${execution}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/x-gzip
        display_name: DSI Artifacts - Execution ${execution}
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: ./build/Documentation/index.html
        remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/${task_name}-${build_id}-index.html
        bucket: mciuploads
        permissions: public-read
        content_type: text/html
        display_name: Documentation
  f_dsi_timeout:
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi on_timeout
  ###

  f_other_post_ops:
      - command: shell.exec
        params:
          working_dir: src
          script: |
            # removes files from the (local) scons cache when it's over a
            # threshold, to the $prune_ratio percentage. Ideally override
            # these default values in the distro config in evergreen.

            if [ -d "${scons_cache_path}" ]; then
                /opt/mongodbtoolchain/v3/bin/python3 buildscripts/scons_cache_prune.py --cache-dir ${scons_cache_path} --cache-size ${scons_cache_size|200} --prune-ratio ${scons_prune_ratio|0.8}
            fi
  f_other_pre_ops:
    - &f_other_pre_ops
      command: shell.exec
      params:
        silent: true
        script: |
          for PS in mongo{,d,s,import,export,dump,restore,stat,files,top,bridge} resmoke.py python{,2} lldb _test; do
              pkill -9 "$PS"
          done
  f_other_timeout:
    # Can't be empty so just `echo`.
    - command: shell.exec
      params: {script: "echo"}

  ###
  # Compile
  compile mongodb:
    # We create a virtual environment with the Python dependencies for compiling the server
    # installed.
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          /opt/mongodbtoolchain/v3/bin/virtualenv --python /opt/mongodbtoolchain/v3/bin/python3 "${workdir}/compile_venv"
          /opt/mongodbtoolchain/v3/bin/virtualenv --python /opt/mongodbtoolchain/v3/bin/python2 "${workdir}/venv"
          source "${workdir}/compile_venv/bin/activate"

          python -m pip install -r etc/pip/compile-requirements.txt

    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          mkdir -p mongodb/bin

          # We get the raw version string (r1.2.3-45-gabcdef) from git
          MONGO_VERSION=$(git describe --abbrev=7)

          # If this is a patch build, we add the patch version id to the version string so we know
          # this build was a patch, and which evergreen task it came from
          if [ "${is_patch|false}" = "true" ]; then
            MONGO_VERSION="$MONGO_VERSION-patch-${version_id}"
          fi

          # This script converts the generated version string into a sanitized version string for
          # use by scons and uploading artifacts as well as information about for the scons cache.
          source "${workdir}/compile_venv/bin/activate"
          MONGO_VERSION=$MONGO_VERSION USE_SCONS_CACHE=${use_scons_cache|false} python buildscripts/generate_compile_expansions.py --out compile_expansions.yml
    - command: expansions.update
      params:
        file: src/compile_expansions.yml
    - command: shell.exec
      params:
        working_dir: src/mongo-tools/src/github.com/mongodb/mongo-tools
        script: |
          set -o verbose
          set -o errexit

          # make sure newlines in the scripts are handled correctly by windows
          if [ "Windows_NT" = "$OS" ]; then
            set -o igncr
          fi;

          # set_goenv provides set_goenv(), print_ldflags() and print_tags() used below
          . ./set_goenv.sh
          GOROOT="" set_goenv || exit
          go version

          build_tools="bsondump mongostat mongofiles mongoexport mongoimport mongorestore mongodump mongotop"
          if [ "${build_mongoreplay}" = "true" ]; then
              build_tools="$build_tools mongoreplay"
          fi
          for i in $build_tools; do
              go build -ldflags "$(print_ldflags)" ${args} -tags "$(print_tags ${tooltags})" -o "../../../../../mongodb/bin/$i${exe|}" $i/main/$i.go
              "../../../../../mongodb/bin/$i${exe|}" --version
          done
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          source "${workdir}/compile_venv/bin/activate"
          python ./buildscripts/scons.py ${compile_flags|} ${scons_cache_args|} install-core MONGO_VERSION=${version} DESTDIR=$(pwd)/mongodb ${patch_compile_flags|}
          mkdir -p mongodb/jstests/hooks
          if [ -d jstests/hooks ]
          then
            echo "Fetching JS test DB correctness checks from directory jstests"
            cp -a jstests/* mongodb/jstests

            echo "Now adding our own special run_validate_collections.js wrapper"
            mv mongodb/jstests/hooks/run_validate_collections.js mongodb/jstests/hooks/run_validate_collections.actual.js

            cat << EOF > mongodb/jstests/hooks/run_validate_collections.js
            print("NOTE: run_validate_collections.js will skip the oplog!");
            TestData = { skipValidationNamespaces: ['local.oplog.rs'] };
            load('jstests/hooks/run_validate_collections.actual.js');
          EOF
          fi
          tar czf mongodb${compile-variant|}.tar.gz mongodb
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb${compile-variant|}.tar.gz
        remote_file: ${project_dir}/${version_id}/${revision}/${platform}/mongodb${compile-variant|}-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb${compile-variant|}.tar.gz
  ###

  ## Schedule Tasks ##
  f_schedule_tasks:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          genny: ${genny_rev}
          signal-processing: ${signal-processing_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          tsbs: ${tsbs_rev}
          workloads: ${workloads_rev}
          mongo-perf: ${mongo-perf_rev}
          YCSB: ${YCSB_rev}
          benchmarks: ${benchmarks_rev}
          py-tpcc: ${py-tpcc_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi schedule_tasks --tasks=${tasks}
    - command: generate.tasks
      params:
        files:
          - build/TaskJSON/Tasks.json


tasks:
  ###
  # Same in every DSI project
  - name: schedule_global_auto_tasks
    priority: 5
    commands:
      - func: f_schedule_tasks
        vars:
          tasks: all_tasks
  - name: schedule_variant_auto_tasks
    priority: 5
    commands:
      - func: f_schedule_tasks
        vars:
          tasks: variant_tasks
  - name: schedule_patch_auto_tasks
    priority: 5
    commands:
      - func: f_schedule_tasks
        vars:
          tasks: patch_tasks
  - name: smoke_test
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
  - name: smoke_test_ssl
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: replica-ssl
          infrastructure_provisioning: replica
  - name: smoke_test_standalone_auth
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: standalone-auth
          infrastructure_provisioning: single
  - name: smoke_test_replset_auth
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: replica-auth
          infrastructure_provisioning: replica
  - name: smoke_test_shard_lite_auth
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: shard-lite-auth
          infrastructure_provisioning: shard-lite
  - name: dsi_integ_test_run_command_simple
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: run_command_simple
  ###

  - name: compile
    commands:
      - command: manifest.load
      - command: git.get_project
        params:
          directory: src
          revisions:
            enterprise: ${enterprise_rev}
            mongo-tools: ${mongo-tools_rev}
      - func: "compile mongodb"

  - name: renew_ssl_cert
    commands:
      - command: git.get_project
        params:
          directory: *src_dir
          revisions:
            dsi: ${dsi_rev}
      # Run the script to generate ssl cert files
      - command: shell.exec
        params:
          script: AWS_ACCESS_KEY_ID=${terraform_key} AWS_SECRET_ACCESS_KEY=${terraform_secret} ./src/dsi/run-dsi generate_ssl_cert
      # Upload files for further DSI usage
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: member.pem
          # path to the remote file is intended to be static
          remote_file: dsi/ssl/member.pem
          bucket: mciuploads
          # the visibility has to be public for consumption by DSI
          permissions: public-read
          content_type: text/plain
          display_name: member.pem
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: root.crt
          # path to the remote file is intended to be static
          remote_file: dsi/ssl/root.crt
          bucket: mciuploads
          # the visibility has to be public for consumption by DSI
          permissions: public-read
          content_type: text/plain
          display_name: root.crt

  - name: linkbench
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "linkbench"

  - name: linkbench_stepdowns
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "linkbench_stepdowns"

  - name: linkbench_rolling_restarts
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "linkbench_rolling_restarts"

  - name: linkbench_non_retryable_writes_stepdowns
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "linkbench_non_retryable_writes_stepdowns"

  - name: linkbench_non_retryable_writes_rolling_restarts
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "linkbench_non_retryable_writes_rolling_restarts"

  - name: linkbench2
    priority: 5
    exec_timeout_secs: 43200 # 12 hours
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "linkbench2"
          additional_tfvars: "tags: {expire-on-delta: 12}"

  - name: tsbs_load
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "tsbs_load"

  - name: tsbs_query
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "tsbs_query"

  - name: tsbs_query_manual_bucketing
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "tsbs_query_manual_bucketing"

  - name: tpcc
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "tpcc"

  - name: industry_benchmarks
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb"

  - name: ycsb_60GB
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb-60GB"

  - name: industry_benchmarks_secondary_reads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb-secondary-reads"

  - name: industry_benchmarks_wmajority
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb-wmajority"

  - name: industry_benchmarks_stepdowns
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb_stepdowns"

  - name: industry_benchmarks_rolling_restarts
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb_rolling_restarts"

  - name: industry_benchmarks_non_retryable_writes_stepdowns
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb_non_retryable_writes_stepdowns"

  - name: industry_benchmarks_non_retryable_writes_rolling_restarts
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "ycsb_non_retryable_writes_rolling_restarts"

  - name: crud_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "crud_workloads"

  - name: crud_workloads_majority
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "crud_workloads_majority"

  - name: cursor_manager
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "cursor_manager"

  - name: mixed_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "mixed_workloads"

  - name: mixed_workloads_genny_stepdowns
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "mixed_workloads_genny_stepdowns"

  - name: mixed_workloads_genny_rolling_restarts
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "mixed_workloads_genny_rolling_restarts"

  - name: big_update_10k
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "BigUpdate10k"

  - name: misc_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "misc_workloads"


  - name: map_reduce_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "map_reduce_workloads"

  - name: genny_canaries
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "genny_canaries"

  - name: retryable_writes_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "retryable_writes"

  - name: snapshot_reads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "snapshot_reads"

  - name: secondary_reads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "secondary_reads"

  - name: bestbuy_agg
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "bestbuy_agg"

  - name: bestbuy_agg_merge_same_db
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "bestbuy_agg_merge_same_db"

  - name: bestbuy_agg_merge_different_db
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "bestbuy_agg_merge_different_db"

  - name: bestbuy_agg_merge_target_hashed
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "bestbuy_agg_merge_target_hashed"

  - name: bestbuy_agg_merge_wordcount
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "bestbuy_agg_merge_wordcount"

  - name: bestbuy_query
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "bestbuy_query"

  - name: non_sharded_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "non_sharded"

  - name: mongos_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "mongos"

  - name: mongos_large_catalog_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "mongos_large_catalog"

  - name: move_chunk_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "move_chunk"

  - name: move_chunk_waiting_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "move_chunk_waiting"

  - name: move_chunk_large_chunk_map_workloads
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "move_chunk_large_chunk_map"

  - name: refine_shard_key_transaction_stress
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "refine_shard_key_transaction_stress"

  - name: secondary_performance
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          # Unfortunately the dash/underscore style is different for mongodb_setup and test_control
          test_control: "secondary_performance"
          mongodb_setup: "secondary-performance"

  - name: initialsync
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "initialsync"

  - name: initialsync-logkeeper-short
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "initialsync-logkeeper"
          mongodb_setup: "initialsync-logkeeper-short"
          # Logkeeper dataset with FCV set to 5.0
          mongodb_dataset: "https://s3-us-west-2.amazonaws.com/dsi-donot-remove/InitialSyncLogKeeper/logkeeper-slice-data-mongodb-5.0.tgz"

  - name: initialsync-logkeeper
    priority: 5
    exec_timeout_secs: 216000 # 2.5 days
    commands:
      - func: f_run_dsi_workload
        timeout_secs: 216000 # 2.5 days
        vars:
          test_control: "initialsync-logkeeper"

  # The following two initial sync logkeeper automation tasks are only used in the commented-out
  # "Linux ReplSet Initial Sync LogKeeper Snapshot Update" variant below and are only intended to be
  # run in patch builds to update FCV for logkeeper datasets.
  - name: initialsync-logkeeper-short-s3-update
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "initialsync-logkeeper-short-s3-update"
          mongodb_setup: "initialsync-logkeeper-short-s3-update"
          # Update this to Logkeeper dataset with FCV set to latest after each LTS release.
          mongodb_dataset: "https://s3-us-west-2.amazonaws.com/dsi-donot-remove/InitialSyncLogKeeper/logkeeper-slice-data-mongodb-5.0.tgz"

  - name: initialsync-logkeeper-snapshot-update
    priority: 5
    exec_timeout_secs: 216000 # 2.5 days
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "initialsync-logkeeper-snapshot-update"

  - name: initialsync-large
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "initialsync-large"

  - name: change_streams_throughput
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "change_streams_throughput"

  - name: change_streams_latency
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "change_streams_latency"

  - name: change_streams_listen_throughput
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "change_streams_listen_throughput"

  - name: change_streams_multi_mongos
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "change_streams_multi_mongos"

  - name: sb_large_scale
    priority: 5
    exec_timeout_secs: 43200 # 12 hours
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "sb_large_scale"
          additional_tfvars: "tags: {expire-on-delta: 12}"

  - name: sb_timeseries
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: "sb_timeseries"


buildvariants:
  - name: task_generation
    display_name: Task Generation
    cron: "0 0 1 1 *" # Every year starting 1/1 at 00:00
    modules: *modules
    expansions:
      platform: linux
      project_dir: dsi
    run_on:
      - amazon2-build
    tasks:
      - name: schedule_global_auto_tasks

  - &compile-amazon2
    name: compile-amazon2
    display_name: Compile
    modules: *modules
    cron: "0 0 * * *" # Everyday at 00:00
    expansions: &compile-expansions
      platform: linux
      project_dir: &project_dir dsi
      tooltags: ""
      use_scons_cache: true
      compile_flags: >-
        --ssl
        --separate-debug
        MONGO_DISTMOD=amazon2
        -j$(grep -c ^processor /proc/cpuinfo)
        --release
        --variables-files=etc/scons/mongodbtoolchain_v3_gcc.vars
        install-mongocryptd
    run_on:
      - "amazon2-xlarge"
    tasks:
      - name: compile

  - name: linux-standalone
    display_name: Linux Standalone
    cron: "0 0 * * *" # Everyday at 00:00
    modules: *modules
    expansions:
      mongodb_setup: standalone
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks: &standalonetasks
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: dsi_integ_test_run_command_simple
      - name: smoke_test
      - name: industry_benchmarks
      - name: ycsb_60GB
      - name: crud_workloads
      - name: genny_canaries
      - name: cursor_manager
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: non_sharded_workloads
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query

  - name: compile-rhel70
    display_name: Compile for Atlas-like
    modules: *modules
    cron: "0 0 * * *" # Everyday at 00:00
    expansions:
      <<: *compile-expansions
      compile_flags: >-
        --ssl
        --separate-debug
        MONGO_DISTMOD=rhel70
        -j$(grep -c ^processor /proc/cpuinfo)
        --release
        --variables-files=etc/scons/mongodbtoolchain_v3_gcc.vars
      compile-variant: -rhel70
    run_on:
      - rhel70-large
    tasks:
      - name: compile

  - name: linux-1-node-replSet
    display_name: Linux 1-Node ReplSet
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: single-replica
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks: &1nodetasks
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: ycsb_60GB
      - name: crud_workloads
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: smoke_test
      - name: retryable_writes_workloads
      - name: non_sharded_workloads
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: snapshot_reads
      - name: linkbench
      - name: linkbench2
      - name: tsbs_load
      - name: tsbs_query
      - name: tsbs_query_manual_bucketing
      - name: tpcc
      - name: industry_benchmarks_wmajority
      - name: sb_large_scale
      - name: sb_timeseries

  - name: linux-standalone-audit
    display_name: Linux Standalone Audit
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: standalone-audit
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: crud_workloads
      - name: smoke_test

  - name: linux-1-node-replSet-fle
    display_name: Linux 1-Node ReplSet FLE
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: single-replica-fle
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      fle: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: linkbench

  - name: linux-1-node-replSet-cwrwc
    display_name: Linux 1-Node ReplSet CWRWC
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: single-replica-cwrwc
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: linkbench

  - name: linux-1-node-replSet-ese-cbc
    display_name: Linux 1-Node ReplSet ESE CBC
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: single-replica-ese-cbc
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: smoke_test
      - name: ycsb_60GB

  - name: linux-1-node-replSet-ese-gcm
    display_name: Linux 1-Node ReplSet ESE GCM
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: single-replica-ese-gcm
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: smoke_test
      - name: ycsb_60GB

  - name: linux-1-node-15gbwtcache
    display_name: Linux 1-Node ReplSet 15 GB WiredTiger Cache
    cron: "0 0 * * 0,2,4" # 00:00 on Sunday,Tuesday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: single-replica-15gbwtcache
      infrastructure_provisioning: single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-single"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: smoke_test

  - name: linux-3-node-1dayhistory-15gbwtcache
    display_name: Linux 3-Node ReplSet 1 Day History 15 GB WiredTiger Cache
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-1dayhistory-15gbwtcache
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: crud_workloads
      - name: crud_workloads_majority
      - name: smoke_test

  - name: linux-3-shard
    display_name: Linux 3-Shard Cluster
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: shard
      infrastructure_provisioning: shard
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-shard"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: crud_workloads
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: smoke_test
      - name: industry_benchmarks_wmajority
      - name: mongos_workloads
      - name: mongos_large_catalog_workloads
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: change_streams_multi_mongos

  - name: linux-shard-lite-audit
    display_name: Linux Shard Lite Cluster Audit
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: shard-lite-audit
      infrastructure_provisioning: shard-lite
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-shard-lite"
    depends_on: *_compile_amazon2
    tasks:
      - name: industry_benchmarks

  - name: linux-shard-lite
    display_name: Linux Shard Lite Cluster
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: shard-lite
      infrastructure_provisioning: shard-lite
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-shard-lite"
    depends_on: *_compile_amazon2
    tasks: &shardlitetasks
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_target_hashed
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query
      - name: change_streams_latency
      - name: change_streams_throughput
      - name: change_streams_listen_throughput
      - name: industry_benchmarks
      - name: industry_benchmarks_wmajority
      - name: linkbench
      - name: mixed_workloads
      - name: mongos_workloads
      - name: mongos_large_catalog_workloads
      - name: move_chunk_large_chunk_map_workloads
      - name: move_chunk_workloads
      - name: move_chunk_waiting_workloads
      - name: retryable_writes_workloads
      - name: smoke_test

  - name: linux-shard-lite-cwrwc
    display_name: Linux Shard Lite Cluster CWRWC
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: shard-lite-cwrwc
      infrastructure_provisioning: shard-lite
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-shard-lite"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: linkbench

  - name: linux-shard-lite-read-concern-available
    display_name: Linux Shard Lite ReadConcern Available
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: shard-lite-read-concern-available
      infrastructure_provisioning: shard-lite
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-shard-lite"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: linkbench

  - name: linux-shard-single
    display_name: Linux Shard Single
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: shard-single
      infrastructure_provisioning: shard-single
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-shard-lite"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks

  - name: linux-3-node-replSet
    display_name: Linux 3-Node ReplSet
    cron: "0 0 * * *" # Everyday at 00:00
    modules: *modules
    expansions:
      mongodb_setup: replica
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks: &3nodetasks
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: ycsb_60GB
      - name: industry_benchmarks_secondary_reads
      - name: crud_workloads
      - name: crud_workloads_majority
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: refine_shard_key_transaction_stress
      - name: smoke_test
      - name: retryable_writes_workloads
      - name: industry_benchmarks_wmajority
      - name: secondary_performance # Uses a special 2 node mongodb setup
      - name: non_sharded_workloads
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: snapshot_reads
      - name: secondary_reads
      - name: tpcc
      - name: linkbench
      - name: linkbench2
      - name: tsbs_load
      - name: tsbs_query
      - name: tsbs_query_manual_bucketing
      - name: sb_large_scale
      - name: sb_timeseries
      - name: big_update_10k

  - name: linux-3-node-replSet-last-continuous-fcv
    display_name: Linux 3-Node ReplSet (Last Continuous FCV)
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-last-continuous-fcv
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: ycsb_60GB
      - name: industry_benchmarks_secondary_reads
      - name: crud_workloads
      - name: crud_workloads_majority
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: refine_shard_key_transaction_stress
      - name: smoke_test
      - name: retryable_writes_workloads
      - name: industry_benchmarks_wmajority
      - name: secondary_performance # Uses a special 2 node mongodb setup
      - name: non_sharded_workloads
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: snapshot_reads
      - name: secondary_reads
      - name: tpcc
      - name: linkbench
      - name: linkbench2
      # Time-series collections are available since v5.0.
      # - name: tsbs_load
      # - name: tsbs_query
      # - name: tsbs_query_manual_bucketing
      - name: sb_large_scale
      - name: sb_timeseries

  - name: linux-3-node-replSet-last-lts-fcv
    display_name: Linux 3-Node ReplSet (Last LTS FCV)
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-last-lts-fcv
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: ycsb_60GB
      - name: industry_benchmarks_secondary_reads
      - name: crud_workloads
      - name: crud_workloads_majority
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: refine_shard_key_transaction_stress
      - name: smoke_test
      - name: retryable_writes_workloads
      - name: industry_benchmarks_wmajority
      - name: secondary_performance # Uses a special 2 node mongodb setup
      - name: non_sharded_workloads
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: snapshot_reads
      - name: secondary_reads
      - name: tpcc
      - name: linkbench
      - name: linkbench2
      # Time-series collections are available since v5.0.
      # - name: tsbs_load
      # - name: tsbs_query
      # - name: tsbs_query_manual_bucketing
      - name: sb_large_scale
      - name: sb_timeseries

  - name: linux-3-node-replSet-noflowcontrol
    display_name: Linux 3-Node ReplSet (Flow Control off)
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-noflowcontrol
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: industry_benchmarks_secondary_reads
      - name: crud_workloads
      - name: crud_workloads_majority
      - name: mixed_workloads
      - name: smoke_test
      - name: industry_benchmarks_wmajority
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: tpcc
      - name: linkbench
      - name: linkbench2

  - name: linux-3-node-replSet-ssl
    display_name: Linux 3-Node ReplSet (SSL)
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-ssl
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: mixed_workloads

  - name: linux-3-node-replSet-maintenance-events
    display_name: Linux 3-Node ReplSet (Maintenance Events)
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-maintenance-events
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks_stepdowns
      - name: industry_benchmarks_rolling_restarts
      - name: industry_benchmarks_non_retryable_writes_stepdowns
      - name: industry_benchmarks_non_retryable_writes_rolling_restarts
      - name: linkbench_stepdowns
      - name: linkbench_rolling_restarts
      - name: linkbench_non_retryable_writes_stepdowns
      - name: linkbench_non_retryable_writes_rolling_restarts
      - name: mixed_workloads_genny_stepdowns
      - name: mixed_workloads_genny_rolling_restarts

  - name: linux-3-node-replSet-initialsync
    display_name: Linux 3-Node ReplSet Initial Sync
    cron: "0 0 * * 0,2,4" # 00:00 on Sunday,Tuesday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-2node
      infrastructure_provisioning: replica
      platform: linux
      authentication: disabled
      storageEngine: wiredTiger
      project_dir: *project_dir
    depends_on: *_compile_amazon2
    run_on:
      - "rhel70-perf-replset"
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: initialsync
      - name: initialsync-logkeeper-short
      - name: initialsync-large

  - name: linux-replSet-initialsync-logkeeper
    display_name: Linux ReplSet Initial Sync LogKeeper
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: initialsync-logkeeper
      infrastructure_provisioning: initialsync-logkeeper
      # EBS logkeeper snapshot with FCV set to 5.0
      snapshotId: snap-0cc5e61399e2e79f6
      platform: linux
      authentication: disabled
      storageEngine: wiredTiger
      project_dir: *project_dir
    run_on:
      - "rhel70-perf-initialsync-logkeeper"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: initialsync-logkeeper

  # Uncomment this to run logkeeper FCV updates automatically. This is only intended to be run in
  # patch builds.
  #- name: linux-replSet-initialsync-logkeeper-snapshot-update
  #  display_name: Linux ReplSet Initial Sync LogKeeper Snapshot Update
  #  cron: "0 0 * * 4" # 00:00 on Thursday
  #  modules: *modules
  #  expansions:
  #    mongodb_setup: initialsync-logkeeper
  #    infrastructure_provisioning: initialsync-logkeeper-snapshot-update
  #    # Update this to latest snapshot after each LTS release.
  #    snapshotId: snap-0dba360e743e27ea0
  #    platform: linux
  #    authentication: disabled
  #    storageEngine: wiredTiger
  #    project_dir: *project_dir
  #  run_on:
  #    - "rhel70-perf-initialsync-logkeeper"
  #  depends_on: *_compile_amazon2
  #  tasks:
  #    - name: schedule_patch_auto_tasks
  #    - name: schedule_variant_auto_tasks
  #    - name: initialsync-logkeeper-snapshot-update
  #    - name: initialsync-logkeeper-short-s3-update

  - name: linux-replSet-audit
    display_name: Linux 3-Node ReplSet Audit
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-audit
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks

  - name: linux-replSet-auth-delay
    display_name: Linux 3-Node ReplSet (Auth Delay)
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    expansions:
      mongodb_setup: replica-auth-cluster-delay
      infrastructure_provisioning: replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
    run_on:
      - "rhel70-perf-replset"
    depends_on: *_compile_amazon2
    tasks:
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks

  - name: atlas-like-M60
    display_name: M60-Like 3-Node ReplSet
    cron: "0 0 * * 0,4" # 00:00 on Sunday,Thursday
    modules: *modules
    expansions:
      mongodb_setup: atlas-like-replica
      infrastructure_provisioning: M60-like-replica
      platform: linux
      project_dir: *project_dir
      authentication: enabled
      storageEngine: wiredTiger
      compile-variant: -rhel70
    run_on:
      - "rhel70-perf-M60-like"
    depends_on: *_compile_rhel70
    tasks:  # Cannot use *3nodetasks because secondary_performance uses a special mongodb setup.
      - name: schedule_patch_auto_tasks
      - name: schedule_variant_auto_tasks
      - name: industry_benchmarks
      - name: ycsb_60GB
      - name: industry_benchmarks_secondary_reads
      - name: crud_workloads
      - name: crud_workloads_majority
      - name: mixed_workloads
      - name: misc_workloads
      - name: map_reduce_workloads
      - name: smoke_test
      - name: retryable_writes_workloads
      - name: industry_benchmarks_wmajority
      - name: non_sharded_workloads
      - name: bestbuy_agg
      - name: bestbuy_agg_merge_different_db
      - name: bestbuy_agg_merge_same_db
      - name: bestbuy_agg_merge_wordcount
      - name: bestbuy_query
      - name: change_streams_throughput
      - name: change_streams_latency
      - name: change_streams_listen_throughput
      - name: snapshot_reads
      - name: secondary_reads
      - name: tpcc
      - name: linkbench
      - name: linkbench2

  - name: renew-ssl-cert
    display_name: Renew SSL Cert
    cron: "0 0 * * 4" # 00:00 on Thursday
    modules: *modules
    run_on:  # Certbot with route53 plugin is installed on RHEL80
      - "rhel80-small"
    tasks:
      - name: renew_ssl_cert
