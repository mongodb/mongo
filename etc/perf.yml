command_type: system
stepback: false

variables:
  ###
  # Leave this section uncommented to enable compile.
  _real_remote_file: &_remote_file
      ${project_dir}/${version_id}/${revision}/${platform}/mongodb${compile-variant|}-${version_id}.tar.gz
  _real_compile: &_compile
    - variant: linux-wt-standalone
      name: compile
  _real_expansions: &_expansion_updates
    []
  ###

  ###
  # **Or**: Leave this section uncommented to bypass/skip compile.
  # # This file â†“ came from a microbenchmarks waterfall run.
  # # https://evergreen.mongodb.com/version/performance_996dcdc3d96346d71f012388eccc79c691619340
  # # Artifacts eventually expire. If this fails, grab the compile artifacts url and update this.
  # _skip_remote_file: &_remote_file
  #     perf/5f6ca2392fbabe40badf39c4/c39af144b2370be0537410d9bc79be66a1a5f3c7/linux/mongodb-5f6ca2392fbabe40badf39c4.tar.gz
  # _skip_compile: &_compile
  #     []
  # _skip_expansions: &_expansion_updates
  #   - key: mongodb_binary_archive
  #     value: https://mciuploads.s3.amazonaws.com/perf/5f6ca2392fbabe40badf39c4/c39af144b2370be0537410d9bc79be66a1a5f3c7/linux/mongodb-5f6ca2392fbabe40badf39c4.tar.gz
  ###

  _src_dir: &src_dir src/mongo
  _modules: &modules
    - enterprise
    - mongo-tools
    - wtdevelop

    - dsi
    - signal-processing
    - genny
    - linkbench
    - linkbench2
    - workloads
    - mongo-perf


modules:
- name: enterprise
  repo: git@github.com:10gen/mongo-enterprise-modules.git
  prefix: src/mongo/db/modules
  branch: v4.4
- name: mongo-tools
  repo: git@github.com:mongodb/mongo-tools.git
  prefix: mongo-tools/src/github.com/mongodb
  branch: master
- name: mongo-perf
  repo: git@github.com:mongodb/mongo-perf.git
  prefix: ../../src
  branch: master

###
# Same in every DSI project
- name: dsi
  repo: git@github.com:10gen/dsi.git
  prefix: ../../src
  branch: master
- name: genny
  repo: git@github.com:10gen/genny.git
  prefix: ../../src
  branch: master
- name: signal-processing
  repo: git@github.com:10gen/signal-processing.git
  prefix: ../../src
  branch: master
- name: workloads
  repo: git@github.com:10gen/workloads.git
  prefix: workloads
  branch: master
- name: wtdevelop
  repo: git@github.com:wiredtiger/wiredtiger.git
  prefix: src/third_party
  branch: develop
- name: linkbench
  repo: git@github.com:10gen/linkbench.git
  prefix: linkbench
  branch: master
- name: linkbench2
  repo: git@github.com:mdcallag/linkbench.git
  prefix: linkbench2
  branch: master
  ref: 63207190657737b32eb0e81c5b81ad1b8bad0e5a
- name: mongo-perf
  repo: git@github.com:mongodb/mongo-perf.git
  prefix: ../../src
  branch: master
###


###
# Same in every DSI project
pre:
    - func: "f_other_pre_ops"
    - func: "f_dsi_pre_run"
post:
    - func: "f_dsi_post_run"
    - func: "f_other_post_ops"
###

functions:
  ###
  # Same in every DSI project
  "f_dsi_pre_run":
    - command: manifest.load
    - command: expansions.update
      params:
        updates: *_expansion_updates
  "f_run_dsi_workload":
    - command: shell.exec
      params:
        script: |
          rm -rf ./*
          mkdir src
    - command: manifest.load
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          genny: ${genny_rev}
          workloads: ${workloads_rev}
          signal-processing: ${signal-processing_rev}
          mongo-perf: ${mongo-perf_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi bootstrap
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi deploy_cluster
    - command: shell.exec
      type: test
      params:
        script: ./src/dsi/run-dsi test_control
    - command: json.send
      params:
        name: "perf"
        file: "./build/LegacyPerfJson/perf.json"
    - command: shell.exec
      type: test
      params:
        script: |
          ./src/dsi/run-dsi analysis
          # detect outliers needs to run, so defer the post_run_check exit status to later
          echo $? > post_run_check.status
    - command: shell.exec
      params:
        script: |
          set -o errexit
          is_patch=${is_patch}
          task_id=${task_id}
          perf_jira_user=${perf_jira_user}
          perf_jira_pw=${perf_jira_pw}
          analysis_user=${dsi_analysis_atlas_user}
          analysis_password=${dsi_analysis_atlas_pw}
          evergreen_api_key=${evergreen_api_key}
          evergreen_api_user=${evergreen_api_user}
          source ./src/dsi/src/signal_processing_setup.sh
    - command: shell.exec
      params:
        script: |
          set -o verbose
          source ./signal_processing_venv/bin/activate
          detect-changes --config .signal-processing.yml --mongo-repo=./src/mongo
    - command: shell.exec
      params:
        script: |
          set -o verbose
          source ./signal_processing_venv/bin/activate
          detect-outliers --config .signal-processing.yml
    - command: shell.exec
      type: setup
      params:
        script: |
          set -o verbose
          filename=rejects.json
          if [ -s "$filename" ]; then
            echo "Rejecting task due to the following outliers:"
            cat "$filename"
            exit ${detected_outlier_exit_code|0}
          fi
    - command: shell.exec
      type: test
      params:
        script: |
          set -o verbose
          exit $(cat post_run_check.status)
  "f_dsi_post_run":
      - command: shell.exec
        params:
          script: ./src/dsi/run-dsi infrastructure_teardown
      - command: shell.exec
        params:
          script: ./src/dsi/run-dsi ./src/dsi/src/dsi/make_artifact.sh
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: dsi-artifacts.tgz
          remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/dsi-artifacts-${task_name}-${build_id}-${execution}.${ext|tgz}
          bucket: mciuploads
          permissions: public-read
          content_type: ${content_type|application/x-gzip}
          display_name: Dsi Artifacts - Execution ${execution}
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: src/mongo/workloads/workloads/jsdoc/jsdocs-redirect.html
          remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/workloads-${task_name}-${build_id}.html
          bucket: mciuploads
          permissions: public-read
          content_type: text/html
          display_name: workloads documentation
      - command: attach.results
        params:
          file_location: report.json
      - command: json.send
        params:
          name: "perf"
          file: "./build/LegacyPerfJson/perf.json"
      - command: s3.put
        params:
          aws_key: ${aws_key}
          aws_secret: ${aws_secret}
          local_file: pip-requirements.txt
          remote_file: ${project}/${build_variant}/${revision}/pip-requirements-${task_id}-${execution}.txt
          bucket: mciuploads
          permissions: public-read
          content_type: atext-plain
          display_name: Pip Requirements
  ###

  "f_other_pre_ops":
    - &f_other_pre_ops
      command: shell.exec
      params:
        silent: true
        script: |
          for PS in mongo{,d,s,import,export,dump,restore,stat,files,top,bridge} resmoke.py python{,2} lldb _test; do
              pkill -9 "$PS"
          done

  "f_other_post_ops":
    - command: s3.put
      params:
            aws_key: ${aws_key}
            aws_secret: ${aws_secret}
            local_file: mongod.log
            remote_file: ${project}/${build_variant}/${revision}/${task_id}/${version_id}/logs/mongod-${build_id}.log
            bucket: mciuploads
            permissions: public-read
            content_type: ${content_type|text/plain}
            display_name: mongod.log
    - *f_other_pre_ops
    - command: shell.exec
      params:
        working_dir: src
        script: |
          # removes files from the (local) scons cache when it's over a
          # threshold, to the $prune_ratio percentage. Ideally override
          # these default values in the distro config in evergreen.

          if [ -d "${scons_cache_path}" ]; then
              /opt/mongodbtoolchain/v3/bin/python3 buildscripts/scons_cache_prune.py --cache-dir ${scons_cache_path} --cache-size ${scons_cache_size|200} --prune-ratio ${scons_prune_ratio|0.8}
          fi

  ###
  # Compile
  "compile mongodb":
    # We create a virtual environment with the Python dependencies for compiling the server
    # installed.
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          /opt/mongodbtoolchain/v3/bin/virtualenv --python /opt/mongodbtoolchain/v3/bin/python3 "${workdir}/compile_venv"
          /opt/mongodbtoolchain/v3/bin/virtualenv --python /opt/mongodbtoolchain/v3/bin/python2 "${workdir}/venv"
          source "${workdir}/compile_venv/bin/activate"

          python -m pip install -r etc/pip/compile-requirements.txt

    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          mkdir -p mongodb/bin

          # We get the raw version string (r1.2.3-45-gabcdef) from git
          MONGO_VERSION=$(git describe --abbrev=7)

          # If we're going to compile the upstream wtdevelop repository for wiredtiger, add
          # that githash to version string.
          if [ "${compile-variant|}" = "-wtdevelop" ]; then
            WT_VERSION=$(cd src/third_party/wtdevelop; git describe --abbrev=7 | cut -c 9-)
            MONGO_VERSION="$MONGO_VERSION-wtdevelop-$WT_VERSION"
          fi
          # If this is a patch build, we add the patch version id to the version string so we know
          # this build was a patch, and which evergreen task it came from
          if [ "${is_patch|false}" = "true" ]; then
            MONGO_VERSION="$MONGO_VERSION-patch-${version_id}"
          fi

          # This script converts the generated version string into a sanitized version string for
          # use by scons and uploading artifacts as well as information about for the scons cache.
          source "${workdir}/compile_venv/bin/activate"
          MONGO_VERSION=$MONGO_VERSION USE_SCONS_CACHE=${use_scons_cache|false} python buildscripts/generate_compile_expansions.py --out compile_expansions.yml
    - command: expansions.update
      params:
        file: src/compile_expansions.yml
    - command: shell.exec
      params:
        working_dir: src/mongo-tools/src/github.com/mongodb/mongo-tools
        script: |
          set -o verbose
          set -o errexit

          # make sure newlines in the scripts are handled correctly by windows
          if [ "Windows_NT" = "$OS" ]; then
            set -o igncr
          fi;

          # set_goenv provides set_goenv(), print_ldflags() and print_tags() used below
          . ./set_goenv.sh
          GOROOT="" set_goenv || exit
          go version

          build_tools="bsondump mongostat mongofiles mongoexport mongoimport mongorestore mongodump mongotop"
          if [ "${build_mongoreplay}" = "true" ]; then
              build_tools="$build_tools mongoreplay"
          fi
          for i in $build_tools; do
              go build -ldflags "$(print_ldflags)" ${args} -tags "$(print_tags ${tooltags})" -o "../../../../../mongodb/bin/$i${exe|}" $i/main/$i.go
              "../../../../../mongodb/bin/$i${exe|}" --version
          done
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          source "${workdir}/compile_venv/bin/activate"
          python ./buildscripts/scons.py ${compile_flags|} ${scons_cache_args|} install-core MONGO_VERSION=${version} DESTDIR=$(pwd)/mongodb
          mkdir -p mongodb/jstests/hooks
          if [ -d jstests/hooks ]
          then
            echo "Fetching JS test DB correctness checks from directory jstests"
            cp -a jstests/* mongodb/jstests

            echo "Now adding our own special run_validate_collections.js wrapper"
            mv mongodb/jstests/hooks/run_validate_collections.js mongodb/jstests/hooks/run_validate_collections.actual.js

            cat << EOF > mongodb/jstests/hooks/run_validate_collections.js
            print("NOTE: run_validate_collections.js will skip the oplog!");
            TestData = { skipValidationNamespaces: ['local.oplog.rs'] };
            load('jstests/hooks/run_validate_collections.actual.js');
          EOF
          fi
          tar czf mongodb${compile-variant|}.tar.gz mongodb
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb${compile-variant|}.tar.gz
        remote_file: ${project_dir}/${version_id}/${revision}/${platform}/mongodb${compile-variant|}-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb${compile-variant|}.tar.gz
  ###


  # This gets replaced by mongodb_setup
  "f_start_server": &f_start_server
    - command: s3.get
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        remote_file: *_remote_file
        bucket: mciuploads
        local_file: src/mongodb.tar.gz
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -e
          set -v
          tar xf mongodb.tar.gz
    - command: shell.exec
      params:
        background: true
        working_dir: src
        script: |
          set -e
          set -o verbose
          mkdir -p ./dbdata
          echo -e "my secret key" > "${workdir}/key"
          chmod 600 "${workdir}/key"
          # We provide the key file for mongod here, rather than in mongod_flags next to the --auth
          # option, because the path to key file requires expanding the {workdir} variable.
          ${mongod_exec_wrapper} ./mongodb/bin/mongod --dbpath ./dbdata ${mongod_flags} --keyFile "${workdir}/key" --logpath "${workdir}/mongod.log"
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -e
          set -o verbose
          sleep 5

          # if we started a replset, initiate it and wait for it to become primary
          #
          # Note: This process is always currently started with --nojournal (not a recommended production configuration, see
          #       https://docs.mongodb.com/manual/tutorial/manage-journaling/#disable-journaling).
          #       As a result, writeConcernMajorityJournalDefault can be set to false. If this becomes configurable later
          #       then the correct value should be passed to rs.initiate or getCmdLineOpts needs to interrogated (but
          #       only after db.createUser).
          ./mongodb/bin/mongo --eval "if(db.isMaster().isreplicaset){\
                             rs.initiate({_id: 'test', version: 1, members: [ { _id: 0, host : 'localhost:27017' }], writeConcernMajorityJournalDefault:false});\
                             assert.soon(function(){return db.isMaster().ismaster}, 'no primary');\
                          }"

          # benchRun() authenticates against the admin db, with a user that must has admin access.
          # Note: This is possibly a legacy requirement from times when it would call serverStatus.
          # Btw, when mongod is started without --auth, these should be harmless no-ops
          ./mongodb/bin/mongo --eval "db.createUser({user: 'admin', pwd: 'password', roles:\
                         [ { role: 'root', db: 'admin' } ] })"\
                           admin

          # print the replset config unless this is a standalone
          ./mongodb/bin/mongo --eval "if( db.isMaster().hosts ) { printjson(rs.config()); }" --username admin --password password admin
          echo "MONGOD STARTED."

  # This gets replaced by subset of f_run_dsi_workload's invocation of analysis
  "f_run_analysis": &f_run_analysis
    - command: shell.exec
      params:
        silent: true
        script: |
          set -o errexit
          is_patch=${is_patch}
          task_id=${task_id}
          perf_jira_user=${perf_jira_user}
          perf_jira_pw=${perf_jira_pw}
          analysis_user=${dsi_analysis_atlas_user}
          analysis_password=${dsi_analysis_atlas_pw}
          evergreen_api_key=${evergreen_api_key}
          evergreen_api_user=${evergreen_api_user}
          source ./src/dsi/src/signal_processing_setup.sh
    - command: shell.exec
      params:
        script: |
          set -o verbose
          source ./signal_processing_venv/bin/activate
          detect-changes --config .signal-processing.yml --mongo-repo ./src/mongo
    - command: shell.exec
      params:
        script: |
          set -o errexit
          set -o verbose
          cat > overrides.yml <<EOF
          bootstrap:
            production: true
          test_control:
            reports_dir_basename: ..
          runtime:
            # evergreen default expansions
            is_patch: ${is_patch}
            task_id: ${task_id}
          EOF
          cp ./src/dsi/configurations/analysis/analysis.microbenchmarks.yml  analysis.yml
    - command: shell.exec
      params:
        silent: true
        script: |
          cat > runtime_secret.yml <<EOF
          dsi_analysis_atlas_user: "${dsi_analysis_atlas_user}"
          dsi_analysis_atlas_pw: "${dsi_analysis_atlas_pw}"
          EOF
          chmod 400 runtime_secret.yml
    - command: shell.exec
      type: test
      params:
        script: ./src/dsi/run-dsi analysis

  # This gets replaced by test_control
  f_run_genny_workload:
    - command: git.get_project
      params:
        directory: src/mongo
        revisions:
          genny: ${genny_rev}
          dsi: ${dsi_rev}
          mongo-perf: ${mongo-perf_rev}
          signal-processing: ${signal-processing_rev}
    - command: shell.exec
      params:
        script: |
          set -eo pipefail
          pushd ./src/genny
              export PATH="/opt/mongodbtoolchain/v3/bin:$PATH"
              python3 -m virtualenv ./venv
              source ./venv/bin/activate
              python3 -m pip install ./src/python

              ./scripts/lamp --linux-distro rhel62
              ./scripts/genny run -w "./dist/etc/genny/workloads/${workload}" -u 'mongodb://admin:password@localhost:27017'
              genny-metrics-legacy-report --report-file "${workdir}/perf.json" build/genny-metrics.csv
          popd
    - command: json.send
      params:
        name: "perf"
        file: "./perf.json"

  f_run_perf_tests:
    - command: git.get_project
      params:
        directory: src/mongo
        revisions:
          genny: ${genny_rev}
          dsi: ${dsi_rev}
          mongo-perf: ${mongo-perf_rev}
          signal-processing: ${signal-processing_rev}
    - command: shell.exec
      params:
        working_dir: src/mongo-perf
        script: |
          set -ev
          virtualenv ./venv
          source ./venv/bin/activate
          pip install argparse

          sleep 5
          ${perf_exec_wrapper} python benchrun.py \
              --shell ../mongodb/bin/mongo          \
              -t ${threads}                       \
              --trialCount 5                      \
              -f testcases/*.js                   \
              --readCmd ${readCmd}                \
              --includeFilter ${includeFilter1}   \
              --includeFilter ${includeFilter2}   \
              --excludeFilter ${excludeFilter}    \
              --out ${workdir}/perf.json          \
              --exclude-testbed                   \
              --username admin                    \
              --password password

          echo "Oplog size at end of tests..."
          ../mongodb/bin/mongo        \
              --username admin      \
              --password password   \
              --eval "db.getSiblingDB('local').oplog.rs.totalSize()/1024/1024" \
              admin

    - command: json.send
      params:
        name: "perf"
        file: "./perf.json"

tasks:
###
# Same in every DSI project
- name: genny_generate_all_tasks
  commands:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          genny: ${genny_rev}
          workloads: ${workloads_rev}
          signal-processing: ${signal-processing_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/genny/scripts/genny_auto_tasks.sh all_tasks
    - command: generate.tasks
      params:
        files:
          - build/TaskJSON/Tasks.json
- name: genny_auto_tasks
  commands:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          genny: ${genny_rev}
          workloads: ${workloads_rev}
          signal-processing: ${signal-processing_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/genny/scripts/genny_auto_tasks.sh variant_tasks
    - command: generate.tasks
      params:
        files:
          - build/TaskJSON/Tasks.json
- name: genny_patch_tasks
  commands:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          genny: ${genny_rev}
          workloads: ${workloads_rev}
          signal-processing: ${signal-processing_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/genny/scripts/genny_auto_tasks.sh patch_tasks
    - command: generate.tasks
      params:
        files:
          - build/TaskJSON/Tasks.json
- name: smoke_test
  priority: 5
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: "short"
- name: smoke_test_ssl
  priority: 5
  commands:
    - func: f_run_dsi_workload
      vars:
          test_control: short
          mongodb_setup: replica-ssl
          infrastructure_provisioning: replica
- name: dsi_integ_test_run_command_simple
  priority: 5
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: "run_command_simple"
###

- name: compile
  commands:
    - command: manifest.load
    - command: git.get_project
      params:
        directory: src
        revisions:
          enterprise: ${enterprise_rev}
          wtdevelop: ${wtdevelop_rev}
          mongo-tools: ${mongo-tools_rev}
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          if [ "${compile-variant|}" = "-wtdevelop" ]; then
            cd src/third_party
            for wtdir in dist examples ext lang src test tools ; do
              rm -rf wiredtiger/$wtdir
              mv wtdevelop/$wtdir wiredtiger/
            done
          fi
    - func: "compile mongodb"


- name: genny_scale_InsertRemove
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_genny_workload
      vars:
        workload: scale/InsertRemove.yml
    - func: f_run_analysis
- name: genny_scale_InsertRemove_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: genny_auto_workload
        auto_workload_path: scale/InsertRemove.yml

- name: genny_execution_UserAcquisition
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_genny_workload
      vars:
        workload: execution/UserAcquisition.yml
    - func: f_run_analysis
- name: genny_execution_UserAcquisition_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: genny_auto_workload
        auto_workload_path: execution/UserAcquisition.yml


- name: query
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "query"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: query_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: query,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: views-query
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "query_identityview"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: true
    - func: f_run_analysis
- name: views-query_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: query_identityview,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'true'}


- name: views-aggregation
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "aggregation_identityview"
        includeFilter2: "regression"
        excludeFilter: "none"
        threads: "1"
        readCmd: true
    - func: f_run_analysis
- name: views-aggregation_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: aggregation_identityview,
           include_filter_2: regression,
           exclude_filter: none,
           threads: "1",
           read_cmd: 'true'}

- name: where
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "where"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: where_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: where,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}

- name: update
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "update"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: update_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: update,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: insert
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "insert"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: insert_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: insert,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: wildcard-index-read
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "wildcard_read"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: wildcard-index-read_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: wildcard_read,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: wildcard-index-write
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "wildcard_write"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: wildcard-index-write_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: wildcard_write,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: geo
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "geo"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: geo_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: geo,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: misc
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "command multi remove mixed"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: misc_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: command multi remove mixed,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: singleThreaded
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "single_threaded"
        includeFilter2: "core regression"
        excludeFilter: "none"
        threads: "1"
        readCmd: false
    - func: f_run_analysis
- name: singleThreaded_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: single_threaded,
           include_filter_2: core regression,
           exclude_filter: none,
           threads: "1",
           read_cmd: 'false'}

- name: aggregation
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "aggregation"
        includeFilter2: "regression"
        excludeFilter: "js"
        threads: "1"
        readCmd: false
    - func: f_run_analysis
- name: aggregation_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: aggregation,
           include_filter_2: regression,
           exclude_filter: js,
           threads: "1",
           read_cmd: 'false'}


- name: agg-query-comparison
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "agg_query_comparison"
        includeFilter2: "core regression"
        excludeFilter: "single_threaded"
        threads: "1 2 4 8"
        readCmd: false
    - func: f_run_analysis
- name: agg-query-comparison_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: agg_query_comparison,
           include_filter_2: core regression,
           exclude_filter: single_threaded,
           threads: "1 2 4 8",
           read_cmd: 'false'}


- name: pipeline-updates
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "pipeline-updates"
        includeFilter2: "regression"
        excludeFilter: "none"
        threads: "1 2 4 8"
        readCmd: true
    - func: f_run_analysis
- name: pipeline-updates_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: pipeline-updates,
           include_filter_2: regression,
           exclude_filter: none,
           threads: "1 2 4 8",
           read_cmd: 'true'}


- name: javascript
  depends_on: *_compile
  commands:
    - func: f_start_server
    - func: f_run_perf_tests
      vars:
        includeFilter1: "js"
        includeFilter2: "aggregation"
        excludeFilter: "none"
        threads: "1 2 4 8"
        readCmd: true
    - func: f_run_analysis
- name: javascript_dsi
  depends_on: *_compile
  commands:
    - func: f_run_dsi_workload
      vars:
        test_control: microbenchmarks
        test_control_params: |
          {include_filter_1: js,
           include_filter_2: aggregation,
           exclude_filter: none,
           threads: "1 2 4 8",
           read_cmd: 'true'}


buildvariants:
- name: linux-wt-standalone
  display_name: Standalone Linux inMemory
  batchtime: 90  # 1.5 hours
  modules: *modules
  expansions:
    # We are explicitly tracking the rhel62 variant compile options from evergreen.yml for
    # microbenchmarks, since they run on the centos6 boxes.  If we can get proper artifacts directly
    # from that project, we should do that and remove the compile tasks.
    compile_flags: --ssl --separate-debug MONGO_DISTMOD=rhel62 -j$(grep -c ^processor /proc/cpuinfo) --release --variables-files=etc/scons/mongodbtoolchain_v3_gcc.vars
    mongod_exec_wrapper: &exec_wrapper "numactl --physcpubind=4,5,6,7 -i 1"
    perf_exec_wrapper: &perf_wrapper "numactl --physcpubind=1,2,3 -i 0"
    mongod_flags: >-
      --auth
      --fork
      --inMemoryEngineConfigString 'eviction=(threads_min=1),'
      --inMemorySizeGB 60
      --networkMessageCompressors noop
      --setParameter diagnosticDataCollectionEnabled=false
      --setParameter enableTestCommands=1
      --setParameter ttlMonitorEnabled=false
      --storageEngine inMemory
      --syncdelay 0
    use_scons_cache: true
    platform: linux
    infrastructure_provisioning: microbenchmarks
    mongodb_setup: microbenchmarks_standalone
    canaries: none
    storageEngine: inMemory
    project_dir: &project_dir perf
  run_on:
  - "centos6-perf"
  tasks:
  - name: compile
    distros:
    - rhel62-large
  - name: genny_scale_InsertRemove
  - name: genny_scale_InsertRemove_dsi
  - name: genny_execution_UserAcquisition
  - name: genny_execution_UserAcquisition_dsi
  - name: aggregation
  - name: aggregation_dsi
  - name: agg-query-comparison
  - name: agg-query-comparison_dsi
  - name: query
  - name: query_dsi
  - name: views-aggregation
  - name: views-aggregation_dsi
  - name: views-query
  - name: views-query_dsi
  - name: where
  - name: where_dsi
  - name: update
  - name: update_dsi
  - name: insert
  - name: insert_dsi
  - name: wildcard-index-read
  - name: wildcard-index-read_dsi
  - name: wildcard-index-write
  - name: wildcard-index-write_dsi
  - name: geo
  - name: geo_dsi
  - name: misc
  - name: misc_dsi
  - name: singleThreaded
  - name: singleThreaded_dsi
  - name: pipeline-updates
  - name: pipeline-updates_dsi
  - name: javascript
  - name: javascript_dsi


- name: linux-wt-repl
  display_name: 1-Node ReplSet Linux inMemory
  batchtime: 90  # 1.5 hours
  modules: *modules
  expansions:
    mongod_exec_wrapper: *exec_wrapper
    perf_exec_wrapper: *perf_wrapper
    mongod_flags: >-
      --auth
      --fork
      --inMemoryEngineConfigString 'eviction=(threads_min=1),'
      --inMemorySizeGB 60
      --networkMessageCompressors noop
      --oplogSize 30000
      --replSet test
      --setParameter diagnosticDataCollectionEnabled=false
      --setParameter enableTestCommands=1
      --setParameter ttlMonitorEnabled=false
      --storageEngine inMemory
      --syncdelay 0
    platform: linux
    infrastructure_provisioning: microbenchmarks
    mongodb_setup: microbenchmarks_replica
    canaries: none
    storageEngine: inMemory
    project_dir: *project_dir
  run_on:
  - "centos6-perf"
  tasks:
  - name: genny_scale_InsertRemove
  - name: genny_scale_InsertRemove_dsi
  - name: update
  - name: update_dsi
  - name: insert
  - name: insert_dsi
  - name: misc
  - name: misc_dsi
  - name: singleThreaded
  - name: singleThreaded_dsi
  - name: wildcard-index-write
  - name: wildcard-index-write_dsi
  - name: pipeline-updates
  - name: pipeline-updates_dsi
