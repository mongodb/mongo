command_type: system
stepback: false

## Parameters for parameterized builds (see https://github.com/evergreen-ci/evergreen/wiki/Parameterized-Builds)
parameters:
  - key: patch_compile_flags
    description: "Additional SCons flags to be applied during scons compile invocations in this patch"

variables:
  ###
  # Leave this section uncommented to enable compile.
  _real_remote_file: &_remote_file
      ${project_dir}/${version_id}/${revision}/${platform}/mongodb${compile-variant|}-${version_id}.tar.gz
  _real_compile: &_compile
    - variant: linux-wt-standalone
      name: compile
  _real_expansions: &_expansion_updates
      []
  ###

  ###
  # **Or**: Leave this section uncommented to bypass/skip compile.
  # This file â†“ came from a microbenchmarks waterfall run.
  # https://evergreen.mongodb.com/version/performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551
  # Artifacts eventually expire. If this fails, grab the compile artifacts url and update this.
#  _skip_remote_file: &_remote_file
#      /perf/performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551/c0a8cbe58cc46253a94130d2cb64cdd8089b3551/linux/mongodb-performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551.tar.gz
#  _skip_compile: &_compile
#      []
#  _skip_expansions: &_expansion_updates
#    - key: mdb_binary_for_server
#      value: https://mciuploads.s3.amazonaws.com/perf/performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551/c0a8cbe58cc46253a94130d2cb64cdd8089b3551/linux/mongodb-performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551.tar.gz
#    - key: mdb_binary_for_client
#      value: https://mciuploads.s3.amazonaws.com/perf/performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551/c0a8cbe58cc46253a94130d2cb64cdd8089b3551/linux/mongodb-performance_c0a8cbe58cc46253a94130d2cb64cdd8089b3551.tar.gz
  ###

  _src_dir: &src_dir src/mongo
  _modules: &modules
    - enterprise
    - mongo-tools
    - dsi
    - genny
    - signal-processing
    - workloads
    - linkbench
    - linkbench2
    - mongo-perf
    - YCSB
    - benchmarks
    - py-tpcc

modules:
  ###
  # Same in every DSI project. Ensure that this block is synchronized with
  # evergreen-dsitest.yml, atlas/system_perf_atlas.yml, and src/dsi/onboarding.py
  # (search update-repos-here) in this repo, and etc/system_perf.yml and
  # etc/perf.yml in mongodb/mongo
  - name: dsi
    repo: git@github.com:10gen/dsi.git
    prefix: ${workdir}/src
    branch: master
  - name: genny
    repo: git@github.com:10gen/genny.git
    prefix: ${workdir}/src
    branch: microbenchmarks-stable
  - name: signal-processing
    repo: git@github.com:10gen/signal-processing.git
    prefix: ${workdir}/src
    branch: master
  - name: workloads
    repo: git@github.com:10gen/workloads.git
    prefix: ${workdir}/src
    branch: master
  - name: linkbench
    repo: git@github.com:10gen/linkbench.git
    prefix: ${workdir}/src
    branch: master
  - name: linkbench2
    repo: git@github.com:10gen/linkbench2.git
    prefix: ${workdir}/src
    branch: master
  - name: mongo-perf
    repo: git@github.com:mongodb/mongo-perf.git
    prefix: ${workdir}/src
    branch: master
  - name: YCSB
    repo: git@github.com:mongodb-labs/YCSB.git
    prefix: ${workdir}/src
    branch: production
  - name: benchmarks
    repo: git@github.com:mongodb-labs/benchmarks.git
    prefix: ${workdir}/src
    branch: master
  - name: py-tpcc
    repo: git@github.com:mongodb-labs/py-tpcc.git
    prefix: ${workdir}/src
    branch: production

  ###
#  - name: mongo
#    repo: git@github.com:mongodb/mongo.git
#    prefix: ${workdir}/src
#    branch: master
  - name: enterprise
    repo: git@github.com:10gen/mongo-enterprise-modules.git
    prefix: src/mongo/db/modules
    branch: master
  - name: mongo-tools
    repo: git@github.com:mongodb/mongo-tools.git
    prefix: mongo-tools/src/github.com/mongodb
    branch: master


###
# Same in every DSI project
pre:
  - func: f_other_pre_ops
  - func: f_dsi_pre_run
post:
  - func: f_dsi_post_run
  - func: f_other_post_ops
timeout:
  - func: f_dsi_timeout
  - func: f_other_timeout
###

functions:
  ###
  # Same in every DSI project
  f_dsi_pre_run:
    - command: manifest.load
    - command: expansions.update
      params:
        updates: *_expansion_updates
  f_run_dsi_workload:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          genny: ${genny_rev}
          signal-processing: ${signal-processing_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          workloads: ${workloads_rev}
          mongo-perf: ${mongo-perf_rev}
          YCSB: ${YCSB_rev}
          benchmarks: ${benchmarks_rev}
          py-tpcc: ${py-tpcc_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi run_workload
    - command: shell.exec
      type: system
      params:
        script: ./src/dsi/run-dsi determine_failure -m SYSTEM
    - command: shell.exec
      type: setup
      params:
        script: ./src/dsi/run-dsi determine_failure -m SETUP
    - command: shell.exec
      type: test
      params:
        script: ./src/dsi/run-dsi determine_failure -m TEST
  f_dsi_post_run:
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi post_run
    - command: perf.send
      params:
        file: ./build/CedarReports/cedar_report.json
        aws_key: ${terraform_key}
        aws_secret: ${terraform_secret}
        bucket: genny-metrics
        region: us-east-1
        prefix: ${task_id}_${execution}
    - command: attach.results
      params:
        file_location: ./build/EvergreenResultsJson/results.json
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: ./build/Artifacts/DSIArtifacts.tgz
        remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/dsi-artifacts-${task_name}-${build_id}-${execution}.tgz
        bucket: mciuploads
        permissions: public-read
        content_type: application/x-gzip
        display_name: DSI Artifacts - Execution ${execution}
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: ./build/Documentation/index.html
        remote_file: ${project_dir}/${build_variant}/${revision}/${task_id}/${version_id}/logs/${task_name}-${build_id}-index.html
        bucket: mciuploads
        permissions: public-read
        content_type: text/html
        display_name: Documentation
  f_dsi_timeout:
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi on_timeout
  ###

  f_other_post_ops:
      - command: shell.exec
        params:
          working_dir: src
          script: |
            # removes files from the (local) scons cache when it's over a
            # threshold, to the $prune_ratio percentage. Ideally override
            # these default values in the distro config in evergreen.

            if [ -d "${scons_cache_path}" ]; then
                /opt/mongodbtoolchain/v3/bin/python3 buildscripts/scons_cache_prune.py --cache-dir ${scons_cache_path} --cache-size ${scons_cache_size|200} --prune-ratio ${scons_prune_ratio|0.8}
            fi
  f_other_pre_ops:
    - &f_other_pre_ops
      command: shell.exec
      params:
        silent: true
        script: |
          for PS in mongo{,d,s,import,export,dump,restore,stat,files,top,bridge} resmoke.py python{,2} lldb _test; do
              pkill -9 "$PS"
          done
  f_other_timeout:
    # Can't be empty so just `echo`.
    - command: shell.exec
      params: {script: "echo"}

  ###
  # Compile
  compile mongodb:
    # We create a virtual environment with the Python dependencies for compiling the server
    # installed.
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          mkdir -p mongodb/bin

          /opt/mongodbtoolchain/v3/bin/virtualenv --python /opt/mongodbtoolchain/v3/bin/python3 "${workdir}/compile_venv"
          source "${workdir}/compile_venv/bin/activate"

          python -m pip install -r etc/pip/compile-requirements.txt
    - command: expansions.write
      params:
         file: expansions.yml
         redacted: true
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          source "${workdir}/compile_venv/bin/activate"

          # We get the raw version string (r1.2.3-45-gabcdef) from git
          export MONGO_VERSION=$(git describe --abbrev=7)

          # If this is a patch build, we add the patch version id to the version string so we know
          # this build was a patch, and which evergreen task it came from
          if [ "${is_patch|false}" = "true" ]; then
            MONGO_VERSION="$MONGO_VERSION-patch-${version_id}"
          fi

          # This script handles sanitizing the version string for use during SCons build
          # and when pushing artifacts up to S3.
          IS_PATCH=${is_patch|false} IS_COMMIT_QUEUE=${is_commit_queue|false} \
            buildscripts/generate_version_expansions.py --out version_expansions.yml
    - command: expansions.update
      params:
        file: src/version_expansions.yml
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose

          # This script handles whether the SCons cache should be used
          source "${workdir}/compile_venv/bin/activate"
          SCONS_CACHE_MODE=${scons_cache_mode|} USE_SCONS_CACHE=${use_scons_cache|false} \
            IS_PATCH=${is_patch|false} IS_COMMIT_QUEUE=${is_commit_queue|false} \
            python buildscripts/generate_compile_expansions.py --out compile_expansions.yml
    - command: expansions.update
      params:
        file: src/compile_expansions.yml
    - command: shell.exec
      params:
        working_dir: src/mongo-tools/src/github.com/mongodb/mongo-tools
        script: |
          set -o verbose
          set -o errexit

          # make sure newlines in the scripts are handled correctly by windows
          if [ "Windows_NT" = "$OS" ]; then
            set -o igncr
          fi;

          # set_goenv provides set_goenv(), print_ldflags() and print_tags() used below
          . ./set_goenv.sh
          GOROOT="" set_goenv || exit
          go version

          build_tools="bsondump mongostat mongofiles mongoexport mongoimport mongorestore mongodump mongotop"
          if [ "${build_mongoreplay}" = "true" ]; then
              build_tools="$build_tools mongoreplay"
          fi
          for i in $build_tools; do
              go build -ldflags "$(print_ldflags)" ${args} -tags "$(print_tags ${tooltags})" -o "../../../../../mongodb/bin/$i${exe|}" $i/main/$i.go
              "../../../../../mongodb/bin/$i${exe|}" --version
          done
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          source "${workdir}/compile_venv/bin/activate"
          python ./buildscripts/idl/gen_all_feature_flag_list.py --import-dir src --import-dir src/mongo/db/modules/enterprise/src
          mkdir -p mongodb/feature_flags
          cp ./all_feature_flags.txt mongodb/feature_flags
    - command: shell.exec
      params:
        working_dir: src
        script: |
          set -o errexit
          set -o verbose
          source "${workdir}/compile_venv/bin/activate"
          python ./buildscripts/scons.py ${compile_flags|} ${scons_cache_args|} $extra_args install-core install-jstestshell SPLIT_DWARF=0 MONGO_VERSION=${version} DESTDIR=$(pwd)/mongodb ${patch_compile_flags|}
          mkdir -p mongodb/jstests/hooks
          if [ -d jstests/hooks ]
          then
            echo "Fetching JS test DB correctness checks from directory jstests"
            cp -a jstests/* mongodb/jstests

            echo "Now adding our own special run_validate_collections.js wrapper"
            mv mongodb/jstests/hooks/run_validate_collections.js mongodb/jstests/hooks/run_validate_collections.actual.js

            cat << EOF > mongodb/jstests/hooks/run_validate_collections.js
            print("NOTE: run_validate_collections.js will skip the oplog!");
            TestData = { skipValidationNamespaces: ['local.oplog.rs'] };
            load('jstests/hooks/run_validate_collections.actual.js');
          EOF
          fi
          tar czf mongodb${compile-variant|}.tar.gz mongodb
    - command: s3.put
      params:
        aws_key: ${aws_key}
        aws_secret: ${aws_secret}
        local_file: src/mongodb${compile-variant|}.tar.gz
        remote_file: ${project_dir}/${version_id}/${revision}/${platform}/mongodb${compile-variant|}-${version_id}.tar.gz
        bucket: mciuploads
        permissions: public-read
        content_type: ${content_type|application/x-gzip}
        display_name: mongodb${compile-variant|}.tar.gz
  ###

  ## Schedule Tasks ##
  f_schedule_tasks:
    - command: git.get_project
      params:
        directory: *src_dir
        revisions:
          dsi: ${dsi_rev}
          genny: ${genny_rev}
          signal-processing: ${signal-processing_rev}
          linkbench: ${linkbench_rev}
          linkbench2: ${linkbench2_rev}
          workloads: ${workloads_rev}
          mongo-perf: ${mongo-perf_rev}
          YCSB: ${YCSB_rev}
          benchmarks: ${benchmarks_rev}
          py-tpcc: ${py-tpcc_rev}
    - command: expansions.write
      params:
        file: ./expansions.yml
    - command: shell.exec
      params:
        script: ./src/dsi/run-dsi schedule_tasks --tasks=${tasks}
    - command: generate.tasks
      params:
        files:
          - build/TaskJSON/Tasks.json


tasks:
  ###
  # Same in every DSI project
  - name: schedule_global_auto_tasks
    priority: 5
    commands:
      - func: f_schedule_tasks
        vars:
          tasks: all_tasks
  - name: schedule_variant_auto_tasks
    priority: 5
    commands:
      - func: f_schedule_tasks
        vars:
          tasks: variant_tasks
  - name: schedule_patch_auto_tasks
    priority: 5
    commands:
      - func: f_schedule_tasks
        vars:
          tasks: patch_tasks
  - name: smoke_test
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
  - name: smoke_test_ssl
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: replica-ssl
          infrastructure_provisioning: replica
  - name: smoke_test_standalone_auth
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: standalone-auth
          infrastructure_provisioning: single
  - name: smoke_test_replset_auth
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: replica-auth
          infrastructure_provisioning: replica
  - name: smoke_test_shard_lite_auth
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: short
          mongodb_setup: shard-lite-auth
          infrastructure_provisioning: shard-lite
  - name: dsi_integ_test_run_command_simple
    priority: 5
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: run_command_simple
  ###

  - name: compile
    commands:
      - command: manifest.load
      - command: git.get_project
        params:
          directory: src
          revisions:
            enterprise: ${enterprise_rev}
            mongo-tools: ${mongo-tools_rev}
      - func: "compile mongodb"


  - name: genny_execution_UserAcquisition
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: auto_genny_workload
          auto_workload_path: ./src/genny/dist/etc/genny/workloads/execution/UserAcquisition.yml
  - name: genny_scale_InsertRemove
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: auto_genny_workload
          auto_workload_path: ./src/genny/dist/etc/genny/workloads/scale/InsertRemove.yml
  - name: query_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: query,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: query_read_commands_large_dataset
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: query_large_dataset,
             include_filter_2: regression,
             exclude_filter: none,
             threads: "1 4",
             read_cmd: 'true',
             share_dataset: 'true'}
  - name: big_collection
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: query,
             include_filter_2: getmore,
             exclude_filter: none,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: views-query
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: query_identityview,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: views-aggregation
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: aggregation_identityview,
             include_filter_2: regression,
             exclude_filter: none,
             threads: "1",
             read_cmd: 'true'}
  - name: where_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: where,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: update_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: update,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: insert_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: insert,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: wildcard-index-read_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: wildcard_read,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: wildcard-index-write_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: wildcard_write,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: geo_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: geo,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: misc_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: command multi remove mixed,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: misc_custom_filter_default_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          mongodb_setup: microbenchmarks_standalone_custom_filter_default
          test_control_params: |
            {include_filter_1: command multi remove mixed,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: misc_custom_filter_slow_or_sample_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          mongodb_setup: microbenchmarks_standalone_custom_filter_slow_or_sample
          test_control_params: |
            {include_filter_1: command multi remove mixed,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: misc_custom_filter_complex_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          mongodb_setup: microbenchmarks_standalone_custom_filter_complex
          test_control_params: |
            {include_filter_1: command multi remove mixed,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: misc_custom_filter_whole_doc_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          mongodb_setup: microbenchmarks_standalone_custom_filter_whole_doc
          test_control_params: |
            {include_filter_1: command multi remove mixed,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: misc_slowms_everything_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          mongodb_setup: microbenchmarks_standalone_slowms_everything
          test_control_params: |
            {include_filter_1: command multi remove mixed,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: singleThreaded_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: single_threaded,
             include_filter_2: core regression,
             exclude_filter: none,
             threads: "1",
             read_cmd: 'true'}
  - name: aggregation_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: aggregation,
             include_filter_2: regression,
             exclude_filter: js,
             threads: "1",
             read_cmd: 'true'}
  - name: aggregation_read_commands_large_dataset
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: aggregation_large_dataset,
             include_filter_2: regression,
             exclude_filter: js,
             threads: "1 4",
             read_cmd: 'true',
             share_dataset: 'true'}
  - name: agg-query-comparison_read_commands
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: agg_query_comparison,
             include_filter_2: core regression,
             exclude_filter: single_threaded,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: pipeline-updates
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: pipeline-updates,
             include_filter_2: regression,
             exclude_filter: none,
             threads: "1 2 4 8",
             read_cmd: 'true'}
  - name: javascript
    depends_on: *_compile
    commands:
      - func: f_run_dsi_workload
        vars:
          test_control: microbenchmarks
          test_control_params: |
            {include_filter_1: js,
             include_filter_2: aggregation,
             exclude_filter: none,
             threads: "1 2 4 8",
             read_cmd: 'true'}


microbenchmark-buildvariants:
  _linux-wt-standalone: &linux-wt-standalone
    name: linux-wt-standalone
    display_name: Standalone Linux inMemory
    cron: "0 */4 * * *" # Every 4 hours starting at midnight
    modules: *modules
    expansions:
      # We are explicitly tracking the rhel62 variant compile options from evergreen.yml for
      # microbenchmarks, since they run on the centos6 boxes.  If we can get proper artifacts directly
      # from that project, we should do that and remove the compile tasks.
      compile_flags: --ssl --separate-debug MONGO_DISTMOD=rhel62 -j$(grep -c ^processor /proc/cpuinfo) --release --variables-files=etc/scons/mongodbtoolchain_v3_gcc.vars
      mongod_exec_wrapper: &exec_wrapper "numactl --physcpubind=4,5,6,7 -i 1"
      perf_exec_wrapper: &perf_wrapper "numactl --physcpubind=1,2,3 -i 0"
      use_scons_cache: true
      platform: linux
      infrastructure_provisioning: microbenchmarks
      mongodb_setup: microbenchmarks_standalone
      canaries: none
      storageEngine: inMemory
      project_dir: &project_dir perf
    run_on:
    - "centos6-perf"
    tasks:
    - name: compile
      distros:
      - rhel62-large
    - name: big_collection
    - name: genny_scale_InsertRemove
    - name: genny_execution_UserAcquisition
    - name: aggregation_read_commands
    - name: aggregation_read_commands_large_dataset
    - name: agg-query-comparison_read_commands
    - name: query_read_commands
    - name: query_read_commands_large_dataset
    - name: views-aggregation
    - name: views-query
    - name: where_read_commands
    - name: update_read_commands
    - name: insert_read_commands
    - name: wildcard-index-read_read_commands
    - name: wildcard-index-write_read_commands
    - name: geo_read_commands
    - name: misc_read_commands
    - name: misc_custom_filter_default_read_commands
    - name: misc_custom_filter_slow_or_sample_read_commands
    - name: misc_custom_filter_complex_read_commands
    - name: misc_custom_filter_whole_doc_read_commands
    - name: misc_slowms_everything_read_commands
    - name: singleThreaded_read_commands
    - name: pipeline-updates
    - name: javascript

  _linux-wt-repl: &linux-wt-repl
    name: linux-wt-repl
    display_name: 1-Node ReplSet Linux inMemory
    cron: "0 */4 * * *" # Every 4 hours starting at midnight
    modules: *modules
    expansions:
      mongod_exec_wrapper: *exec_wrapper
      perf_exec_wrapper: *perf_wrapper
      platform: linux
      infrastructure_provisioning: microbenchmarks
      mongodb_setup: microbenchmarks_replica
      canaries: none
      storageEngine: inMemory
      project_dir: *project_dir
    run_on:
    - "centos6-perf"
    tasks:
    - name: genny_scale_InsertRemove
    - name: update_read_commands
    - name: insert_read_commands
    - name: misc_read_commands
    - name: singleThreaded_read_commands
    - name: wildcard-index-write_read_commands
    - name: pipeline-updates

buildvariants:
  - *linux-wt-standalone

  - *linux-wt-repl

  - <<: *linux-wt-standalone
    name: linux-wt-standalone-all-feature-flags
    display_name: Standalone Linux inMemory (all feature flags)
    cron: "0 0 * * *" # Every day starting at 00:00
    expansions:
      mongodb_setup: microbenchmarks_standalone-all-feature-flags

  - <<: *linux-wt-standalone
    name: linux-wt-standalone-classic-query-engine
    display_name: Standalone Linux inMemory (Classic Query Engine)
    cron: "0 0 * * 4" # 00:00 on Thursday
    expansions:
      mongodb_setup: microbenchmarks_standalone-classic-query-engine

  - <<: *linux-wt-repl
    name: linux-wt-repl-all-feature-flags
    display_name: 1-Node ReplSet Linux inMemory (all feature flags)
    cron: "0 0 * * *" # Every day starting at 00:00
    expansions:
      mongodb_setup: microbenchmarks_replica-all-feature-flags
