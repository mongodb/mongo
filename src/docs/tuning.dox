/*! @page tuning Performance Tuning

@section tuning_cache_size Cache size

The cache size for the database is configurable by setting the \c
cache_size configuration string when calling the ::wiredtiger_open
function.

The effectiveness of the cache can be measured by reviewing the page
eviction statistics for the database.

An example of setting a cache size to 500MB:

@snippet ex_config.c configure cache size

@section tuning_memory_allocation Memory allocation

The performance of heavily-threaded WiredTiger applications can be
dominated by memory allocation because the WiredTiger engine has to free
and re-allocate memory as part of many queries.  Replacing the system's
malloc implementation with one that has better threaded performance (for
example, Google's
<a href="http://goog-perftools.sourceforge.net/doc/tcmalloc.html">tcmalloc</a>,
or <a href="http://www.canonware.com/jemalloc">jemalloc</a>),
can dramatically improve throughput.

@section tuning_cursor_persistence Cursor persistence

Opening a new cursor is a relatively expensive operation in WiredTiger
(especially in table objects and Log-Structured Merge Trees (LSM) trees,
where a logical cursor may require multiple, underlying object cursors),
and caching cursors can improve performance.  On the other hand, cursors
hold positions in objects, and therefore long-lived cursor positions can
decrease performance.  The best combination is to cache cursors, but use
the WT_CURSOR::reset method to discard the cursor's position in the
object when the position is no longer needed.

Additionally, cursors are automatically reset whenever a transaction
boundary is crossed; when a transaction is started with the
WT_SESSION::begin_transaction or ended with either
WT_SESSION::commit_transaction or WT_SESSION::rollback_transaction, all
open cursors are automatically reset, there is no need to call the
WT_CURSOR::reset method explicitly, and the cursor can be immediately
reused.

@section tuning_read_only_objects Read-only objects

Cursors opened on checkpoints (either named, or using the special "last
checkpoint" name "WiredTigerCheckpoint") are read-only objects.  Unless
memory mapping is configured off (using the "mmap" configuration string
to ::wiredtiger_open), read-only objects are mapped into process memory
instead of being read through the WiredTiger cache.  Using read-only
objects where possible minimizes the amount of buffer cache memory
required by WiredTiger applications and the work required for buffer
cache management, as well as reducing the number of memory copies from
the operating system buffer cache into application memory.

To open a named checkpoint, use the configuration string "checkpoint"
to the WT_SESSION::open_cursor method:
@snippet ex_all.c open a named checkpoint

To open the last checkpoint taken in the object, use the configuration
string "checkpoint" with the name "WiredTigerCheckpoint" to the
WT_SESSION::open_cursor method:
@snippet ex_all.c open the default checkpoint

@section tuning_cache_resident Cache resident objects

Cache resident objects (objects never considered for the purposes of
cache eviction), can be configured with the WT_SESSION::create
"cache_resident" configuration string.

Configuring a cache resident object has two effects: first, once the
object's page have been instantiated in memory, no further I/O cost is
ever paid for object access, minimizing potential latency.  Second,
in-memory objects can be accessed faster than objects tracked for
potential eviction, and applications able to guarantee sufficient memory
that an object need never be evicted can significantly increase their
performance.

An example of configuring a cache-resident object:

@snippet ex_all.c Create a cache-resident object

@section tuning_page_size  Page and overflow sizes

There are four page and item size configuration values: \c internal_page_max,
\c internal_item_max, \c leaf_page_max and \c leaf_item_max.  All four should
be specified to the WT_SESSION::create method, that is, they are configurable
on a per-file basis.

The \c internal_page_max and \c leaf_page_max configuration values specify
the maximum size for Btree internal and leaf pages.  That is, when an
internal or leaf page reaches the specified size, it splits into two pages.
Generally, internal pages should be sized to fit into the system's L1 or L2
caches in order to minimize cache misses when searching the tree, while leaf
pages should be sized to maximize I/O performance (if reading from disk is
necessary, it is usually desirable to read a large amount of data, assuming
some locality of reference in the application's access pattern).

The \c internal_item_max and \c leaf_item_max configuration values specify
the maximum size at which an object will be stored on-page.  Larger items
will be stored separately in the file from the page where the item logically
appears.  Referencing overflow items is more expensive than referencing
on-page items, requiring additional I/O if the object is not already cached.
For this reason, it is important to avoid creating large numbers of overflow
items that are repeatedly referenced, and the maximum item size should
probably be increased if many overflow items are being created.  Because
pages must be large enough to store any item that is not an overflow item,
increasing the size of the overflow items may also require increasing the
page sizes.

With respect to compression, page and item sizes do not necessarily reflect
the actual size of the page or item on disk, if block compression has been
configured.  Block compression in WiredTiger happens within the disk I/O
subsystem, and so a page might split even if subsequent compression would
result in a resulting page size that would be small enough to leave as a
single page.  In other words, page and overflow sizes are based on in-memory
sizes, not disk sizes.

There are two other, related configuration values, also settable by the
WT_SESSION::create method.  They are \c allocation_size, and \c split_pct.

The \c allocation_size configuration value is the underlying unit of
allocation for the file.  As the unit of file allocation, it has two
effects: first, it limits the ultimate size of the file, and second, it
determines how much space is wasted when storing overflow items.

By limiting the size of the file, the allocation size limits the amount
of data that can be stored in a file.  For example, if the allocation
size is set to the minimum possible (512B), the maximum file size is
2TB, that is, attempts to allocate new file blocks will fail when the
file reaches 2TB in size.  If the allocation size is set to the maximum
possible (512MB), the maximum file size is 2EB.

The unit of allocation also determines how much space is wasted when
storing overflow items.  For example, if the allocation size were set
to the minimum value of 512B, an overflow item of 1100 bytes would
require 3 allocation sized file units, or 1536 bytes, wasting almost 500
bytes.  For this reason, as the allocation size increases, page sizes
and overflow item sizes will likely increase as well, to ensure that
significant space isn't wasted by overflow items.

The last configuration value is \c split_pct, which configures the size
of a split page.  When a page grows sufficiently large that it must be
split, the newly split page's size is \c split_pct percent of the
maximum page size.  This value should be selected to avoid creating a
large number of tiny pages or repeatedly splitting whenever new entries
are inserted.  For example, if the maximum page size is 1MB, a \c
split_pct value of 10% would potentially result in creating a large
number of 100KB pages, which may not be optimal for future I/O.   Or, if
the maximum page size is 1MB, a \c split_pct value of 90% would
potentially result in repeatedly splitting pages as the split pages grow
to 1MB over and over.  The default value for \c split_pct is 75%,
intended to keep large pages relatively large, while still giving split
pages room to grow.

An example of configuring page sizes:

@snippet ex_file.c file create

@section tuning_direct_io Direct I/O

WiredTiger optionally supports direct I/O, based on the non-standard \c
O_DIRECT flag to the POSIX 1003.1 open system call.   Configuring direct
I/O may be useful for applications wanting to minimize the operating
system cache effects of I/O to and from WiredTiger's buffer cache.

Direct I/O is configured using the "direct_io" configuration string to
the ::wiredtiger_open function.  An example of configuring direct I/O
for WiredTiger's data files:

@snippet ex_all.c Configure direct_io for data files

@section tuning_checksums Checksums

WiredTiger checksums file reads and writes, by default.  In read-only
applications, or when file compression provides any necessary checksum
functionality, or when using backing storage systems where blocks
require no validation, performance can be increased by turning off
checksum support when calling the WT_SESSION::create method.

Checksums can be configured to be "off" or "on", as well as "uncompressed".
The "uncompressed" configuration checksums blocks not otherwise protected
by compression.   For example, in a system where the compression algorithms
provide sufficient protection against corruption, and when writing a block
which is too small to be usefully compressed, setting the checksum
configuration value to "uncompressed" causes WiredTiger to checksum the
blocks which are not compressed:

@snippet ex_all.c Configure checksums to uncompressed

@section tuning_compression Compression

WiredTiger configures key prefix compression for row-store objects, and
column-store compression for both row-store and column-store objects,
by default.
These forms of compression minimize in-memory and on-disk space, but at
some CPU cost when rows are read and written.   Turning these forms of
compression off may increase application throughput.

For example, turning off row-store key prefix compression:

@snippet ex_all.c Configure key prefix compression off

For example, turning off row-store or column-store dictionary compression:

@snippet ex_all.c Configure dictionary compression off

WiredTiger does not configure Huffman encoding or block compression by
default, but these forms of compression can also impact overall
throughput.  See @ref file_formats_compression for more information.

@section tuning_statistics Performance monitoring with statistics

WiredTiger optionally maintains a variety of statistics, when the
\c statistics configuration string is specified to ::wiredtiger_open;
see @ref statistics for general information about statistics, and
@ref data_statistics for information about accessing the statistics.

Note that maintaining run-time statistics involves updating
shared-memory data structures and may decrease application performance.

The statistics gathered by WiredTiger can be combined to derive information
about the system's behavior.  For example, a cursor can be opened on the
statistics for a table:

@snippet ex_stat.c statistics calculate open table stats

Then this code calculates the "fragmentation" of a table, defined
here as the percentage of the table that is not part of the current
checkpoint:

@snippet ex_stat.c statistics calculate table fragmentation

The following example calculates the "write amplification", defined here as
the ratio of bytes written to the filesystem versus the total bytes
inserted, updated and removed by the application.

@snippet ex_stat.c statistics calculate write amplification

Both examples use this helper function to retrieve statistics values from a
cursor:

@snippet ex_stat.c statistics calculation helper function
 */
